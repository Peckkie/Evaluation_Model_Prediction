{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>Class</th>\n",
       "      <th>SubPosition</th>\n",
       "      <th>Views</th>\n",
       "      <th>Sub_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986295</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.188388</td>\n",
       "      <td>-0.088482</td>\n",
       "      <td>-0.010367</td>\n",
       "      <td>0.424080</td>\n",
       "      <td>-0.112542</td>\n",
       "      <td>0.264733</td>\n",
       "      <td>-0.136909</td>\n",
       "      <td>0.976137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>0.662107</td>\n",
       "      <td>0.186359</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.918636</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P31</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>AB01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236491</td>\n",
       "      <td>0.884337</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.116625</td>\n",
       "      <td>0.468836</td>\n",
       "      <td>0.041453</td>\n",
       "      <td>1.049583</td>\n",
       "      <td>0.551325</td>\n",
       "      <td>-0.031517</td>\n",
       "      <td>0.234770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109788</td>\n",
       "      <td>0.270928</td>\n",
       "      <td>0.725451</td>\n",
       "      <td>-0.128793</td>\n",
       "      <td>-0.162728</td>\n",
       "      <td>0.790094</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P1</td>\n",
       "      <td>FP-A</td>\n",
       "      <td>AB01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024744</td>\n",
       "      <td>0.609714</td>\n",
       "      <td>-0.057803</td>\n",
       "      <td>0.567234</td>\n",
       "      <td>0.702744</td>\n",
       "      <td>-0.176519</td>\n",
       "      <td>1.007505</td>\n",
       "      <td>0.066433</td>\n",
       "      <td>-0.114292</td>\n",
       "      <td>-0.097552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178272</td>\n",
       "      <td>0.166651</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>-0.055177</td>\n",
       "      <td>-0.181716</td>\n",
       "      <td>0.914778</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P2</td>\n",
       "      <td>FP-A</td>\n",
       "      <td>AB01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163779</td>\n",
       "      <td>-0.196792</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>0.037266</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.441722</td>\n",
       "      <td>-0.053995</td>\n",
       "      <td>0.286697</td>\n",
       "      <td>-0.103555</td>\n",
       "      <td>0.605432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180175</td>\n",
       "      <td>0.070436</td>\n",
       "      <td>-0.199377</td>\n",
       "      <td>0.087352</td>\n",
       "      <td>0.147240</td>\n",
       "      <td>0.552130</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P42</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>AB01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.804756</td>\n",
       "      <td>0.100611</td>\n",
       "      <td>-0.142152</td>\n",
       "      <td>-0.020464</td>\n",
       "      <td>0.085910</td>\n",
       "      <td>1.049034</td>\n",
       "      <td>-0.141936</td>\n",
       "      <td>0.542180</td>\n",
       "      <td>-0.020645</td>\n",
       "      <td>0.918757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180178</td>\n",
       "      <td>0.586436</td>\n",
       "      <td>-0.042483</td>\n",
       "      <td>0.119813</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.963566</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P41</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>AB01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.580081</td>\n",
       "      <td>0.081157</td>\n",
       "      <td>-0.202055</td>\n",
       "      <td>-0.055976</td>\n",
       "      <td>-0.038843</td>\n",
       "      <td>0.492340</td>\n",
       "      <td>-0.221081</td>\n",
       "      <td>0.202125</td>\n",
       "      <td>-0.211172</td>\n",
       "      <td>0.944930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201034</td>\n",
       "      <td>0.856926</td>\n",
       "      <td>0.299519</td>\n",
       "      <td>-0.062546</td>\n",
       "      <td>-0.211236</td>\n",
       "      <td>0.801512</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P32</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.163949</td>\n",
       "      <td>-0.138466</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>-0.029014</td>\n",
       "      <td>0.069206</td>\n",
       "      <td>0.480572</td>\n",
       "      <td>-0.203401</td>\n",
       "      <td>0.243316</td>\n",
       "      <td>-0.040707</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111179</td>\n",
       "      <td>0.085379</td>\n",
       "      <td>-0.026939</td>\n",
       "      <td>0.201886</td>\n",
       "      <td>0.154778</td>\n",
       "      <td>0.837904</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P42</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.183155</td>\n",
       "      <td>-0.177661</td>\n",
       "      <td>0.442956</td>\n",
       "      <td>0.408842</td>\n",
       "      <td>-0.182873</td>\n",
       "      <td>-0.219403</td>\n",
       "      <td>-0.187975</td>\n",
       "      <td>-0.091318</td>\n",
       "      <td>0.320332</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007473</td>\n",
       "      <td>-0.174601</td>\n",
       "      <td>-0.214004</td>\n",
       "      <td>0.174360</td>\n",
       "      <td>0.261467</td>\n",
       "      <td>-0.123360</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P52</td>\n",
       "      <td>FP-C</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.203872</td>\n",
       "      <td>-0.200696</td>\n",
       "      <td>0.339431</td>\n",
       "      <td>0.471467</td>\n",
       "      <td>0.163014</td>\n",
       "      <td>-0.194705</td>\n",
       "      <td>-0.198339</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0.560823</td>\n",
       "      <td>-0.132336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754900</td>\n",
       "      <td>-0.126592</td>\n",
       "      <td>-0.221690</td>\n",
       "      <td>0.455701</td>\n",
       "      <td>0.609111</td>\n",
       "      <td>-0.059244</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P61</td>\n",
       "      <td>FP-C</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.123817</td>\n",
       "      <td>-0.223009</td>\n",
       "      <td>-0.219725</td>\n",
       "      <td>-0.156302</td>\n",
       "      <td>0.207813</td>\n",
       "      <td>-0.149565</td>\n",
       "      <td>-0.228558</td>\n",
       "      <td>-0.215155</td>\n",
       "      <td>0.086653</td>\n",
       "      <td>-0.084946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195911</td>\n",
       "      <td>0.314990</td>\n",
       "      <td>-0.243441</td>\n",
       "      <td>-0.079050</td>\n",
       "      <td>-0.224806</td>\n",
       "      <td>0.084775</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P8</td>\n",
       "      <td>FP-E</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 2052 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.986295  0.000214 -0.188388 -0.088482 -0.010367  0.424080 -0.112542   \n",
       "1     0.236491  0.884337  0.001424  0.116625  0.468836  0.041453  1.049583   \n",
       "2    -0.024744  0.609714 -0.057803  0.567234  0.702744 -0.176519  1.007505   \n",
       "3     0.163779 -0.196792  0.010655  0.037266  0.005610  0.441722 -0.053995   \n",
       "4     0.804756  0.100611 -0.142152 -0.020464  0.085910  1.049034 -0.141936   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4595  0.580081  0.081157 -0.202055 -0.055976 -0.038843  0.492340 -0.221081   \n",
       "4596  0.163949 -0.138466  0.005822 -0.029014  0.069206  0.480572 -0.203401   \n",
       "4597 -0.183155 -0.177661  0.442956  0.408842 -0.182873 -0.219403 -0.187975   \n",
       "4598 -0.203872 -0.200696  0.339431  0.471467  0.163014 -0.194705 -0.198339   \n",
       "4599 -0.123817 -0.223009 -0.219725 -0.156302  0.207813 -0.149565 -0.228558   \n",
       "\n",
       "             7         8         9  ...      2042      2043      2044  \\\n",
       "0     0.264733 -0.136909  0.976137  ...  0.011231  0.662107  0.186359   \n",
       "1     0.551325 -0.031517  0.234770  ... -0.109788  0.270928  0.725451   \n",
       "2     0.066433 -0.114292 -0.097552  ... -0.178272  0.166651  0.780952   \n",
       "3     0.286697 -0.103555  0.605432  ... -0.180175  0.070436 -0.199377   \n",
       "4     0.542180 -0.020645  0.918757  ... -0.180178  0.586436 -0.042483   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4595  0.202125 -0.211172  0.944930  ... -0.201034  0.856926  0.299519   \n",
       "4596  0.243316 -0.040707  0.701990  ... -0.111179  0.085379 -0.026939   \n",
       "4597 -0.091318  0.320332 -0.222782  ... -0.007473 -0.174601 -0.214004   \n",
       "4598  0.147333  0.560823 -0.132336  ...  0.754900 -0.126592 -0.221690   \n",
       "4599 -0.215155  0.086653 -0.084946  ... -0.195911  0.314990 -0.243441   \n",
       "\n",
       "          2045      2046      2047     Class  SubPosition  Views  Sub_class  \n",
       "0    -0.018691  0.207207  0.918636  Abnormal          P31   FP-B       AB01  \n",
       "1    -0.128793 -0.162728  0.790094  Abnormal           P1   FP-A       AB01  \n",
       "2    -0.055177 -0.181716  0.914778  Abnormal           P2   FP-A       AB01  \n",
       "3     0.087352  0.147240  0.552130  Abnormal          P42   FP-B       AB01  \n",
       "4     0.119813  0.101700  0.963566  Abnormal          P41   FP-B       AB01  \n",
       "...        ...       ...       ...       ...          ...    ...        ...  \n",
       "4595 -0.062546 -0.211236  0.801512    Normal          P32   FP-B     Normal  \n",
       "4596  0.201886  0.154778  0.837904    Normal          P42   FP-B     Normal  \n",
       "4597  0.174360  0.261467 -0.123360    Normal          P52   FP-C     Normal  \n",
       "4598  0.455701  0.609111 -0.059244    Normal          P61   FP-C     Normal  \n",
       "4599 -0.079050 -0.224806  0.084775    Normal           P8   FP-E     Normal  \n",
       "\n",
       "[4600 rows x 2052 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataframe = pd.read_csv( '/home/yupaporn/codes/USAI/FVtrain_5FP_fold7_1.csv') #เปลี่ยนไฟล์\n",
    "dataframe = dataframe.drop(['Unnamed: 0'], axis=1)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 2048)\n",
      "(4600,)\n"
     ]
    }
   ],
   "source": [
    "X = dataframe.iloc[:,0:2048]\n",
    "y = dataframe.iloc[:,2048]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abnormal'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [400]\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100] \n",
    "\n",
    "forest = RandomForestClassifier(random_state = 1)\n",
    "\n",
    "\n",
    "hyperF ={'n_estimators' : n_estimators, 'max_depth' : max_depth, 'min_samples_split' : min_samples_split}\n",
    "# hyperF ={'max_depth' : max_depth, 'min_samples_split' : min_samples_split}\n",
    "\n",
    "gridF = GridSearchCV(forest, hyperF, cv = 10, verbose = 1, n_jobs = -1)\n",
    "bestF = gridF.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.736739</td>\n",
       "      <td>0.059180</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.734565</td>\n",
       "      <td>0.058247</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.736739</td>\n",
       "      <td>0.058441</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.734783</td>\n",
       "      <td>0.058816</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 15, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.728043</td>\n",
       "      <td>0.063614</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 100, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.058983</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 2, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.062462</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 5, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.771304</td>\n",
       "      <td>0.058959</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 10, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.770870</td>\n",
       "      <td>0.063612</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 15, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.754565</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 100, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.794130</td>\n",
       "      <td>0.067357</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 2, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.793261</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.794783</td>\n",
       "      <td>0.064123</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.792391</td>\n",
       "      <td>0.066893</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 15, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.772391</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 100, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.803913</td>\n",
       "      <td>0.063646</td>\n",
       "      <td>{'max_depth': 25, 'min_samples_split': 2, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.801087</td>\n",
       "      <td>0.066219</td>\n",
       "      <td>{'max_depth': 25, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.803043</td>\n",
       "      <td>0.066517</td>\n",
       "      <td>{'max_depth': 25, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.799130</td>\n",
       "      <td>0.065861</td>\n",
       "      <td>{'max_depth': 25, 'min_samples_split': 15, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.772391</td>\n",
       "      <td>0.066892</td>\n",
       "      <td>{'max_depth': 25, 'min_samples_split': 100, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.801957</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 2, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.803913</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 5, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.801087</td>\n",
       "      <td>0.066404</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 10, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.798478</td>\n",
       "      <td>0.066807</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 15, 'n_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.775652</td>\n",
       "      <td>0.064267</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 100, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  \\\n",
       "0          0.736739        0.059180   \n",
       "1          0.734565        0.058247   \n",
       "2          0.736739        0.058441   \n",
       "3          0.734783        0.058816   \n",
       "4          0.728043        0.063614   \n",
       "5          0.770000        0.058983   \n",
       "6          0.770000        0.062462   \n",
       "7          0.771304        0.058959   \n",
       "8          0.770870        0.063612   \n",
       "9          0.754565        0.065934   \n",
       "10         0.794130        0.067357   \n",
       "11         0.793261        0.061882   \n",
       "12         0.794783        0.064123   \n",
       "13         0.792391        0.066893   \n",
       "14         0.772391        0.062871   \n",
       "15         0.803913        0.063646   \n",
       "16         0.801087        0.066219   \n",
       "17         0.803043        0.066517   \n",
       "18         0.799130        0.065861   \n",
       "19         0.772391        0.066892   \n",
       "20         0.801957        0.065517   \n",
       "21         0.803913        0.063950   \n",
       "22         0.801087        0.066404   \n",
       "23         0.798478        0.066807   \n",
       "24         0.775652        0.064267   \n",
       "\n",
       "                                               params  \n",
       "0   {'max_depth': 5, 'min_samples_split': 2, 'n_es...  \n",
       "1   {'max_depth': 5, 'min_samples_split': 5, 'n_es...  \n",
       "2   {'max_depth': 5, 'min_samples_split': 10, 'n_e...  \n",
       "3   {'max_depth': 5, 'min_samples_split': 15, 'n_e...  \n",
       "4   {'max_depth': 5, 'min_samples_split': 100, 'n_...  \n",
       "5   {'max_depth': 8, 'min_samples_split': 2, 'n_es...  \n",
       "6   {'max_depth': 8, 'min_samples_split': 5, 'n_es...  \n",
       "7   {'max_depth': 8, 'min_samples_split': 10, 'n_e...  \n",
       "8   {'max_depth': 8, 'min_samples_split': 15, 'n_e...  \n",
       "9   {'max_depth': 8, 'min_samples_split': 100, 'n_...  \n",
       "10  {'max_depth': 15, 'min_samples_split': 2, 'n_e...  \n",
       "11  {'max_depth': 15, 'min_samples_split': 5, 'n_e...  \n",
       "12  {'max_depth': 15, 'min_samples_split': 10, 'n_...  \n",
       "13  {'max_depth': 15, 'min_samples_split': 15, 'n_...  \n",
       "14  {'max_depth': 15, 'min_samples_split': 100, 'n...  \n",
       "15  {'max_depth': 25, 'min_samples_split': 2, 'n_e...  \n",
       "16  {'max_depth': 25, 'min_samples_split': 5, 'n_e...  \n",
       "17  {'max_depth': 25, 'min_samples_split': 10, 'n_...  \n",
       "18  {'max_depth': 25, 'min_samples_split': 15, 'n_...  \n",
       "19  {'max_depth': 25, 'min_samples_split': 100, 'n...  \n",
       "20  {'max_depth': 30, 'min_samples_split': 2, 'n_e...  \n",
       "21  {'max_depth': 30, 'min_samples_split': 5, 'n_e...  \n",
       "22  {'max_depth': 30, 'min_samples_split': 10, 'n_...  \n",
       "23  {'max_depth': 30, 'min_samples_split': 15, 'n_...  \n",
       "24  {'max_depth': 30, 'min_samples_split': 100, 'n...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results as a pandas DataFrame\n",
    "import pandas as pd\n",
    "pd.DataFrame(bestF.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**examine the first result \n",
      "\n",
      "{'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "0.7367391304347826\n",
      "\n",
      " **print the array of mean scores only \n",
      "\n",
      "[0.73673913 0.73456522 0.73673913 0.73478261 0.72804348 0.77\n",
      " 0.77       0.77130435 0.77086957 0.75456522 0.79413043 0.79326087\n",
      " 0.79478261 0.7923913  0.7723913  0.80391304 0.80108696 0.80304348\n",
      " 0.79913043 0.7723913  0.80195652 0.80391304 0.80108696 0.79847826\n",
      " 0.77565217]\n",
      "\n",
      " **examine the best model \n",
      "\n",
      "0.8039130434782609\n",
      "{'max_depth': 25, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "RandomForestClassifier(max_depth=25, n_estimators=400, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "# examine the first result\n",
    "print(\"**examine the first result\",\"\\n\")\n",
    "\n",
    "print(bestF.cv_results_['params'][0])\n",
    "print(bestF.cv_results_['mean_test_score'][0])\n",
    "\n",
    "# print the array of mean scores only\n",
    "print(\"\\n\",\"**print the array of mean scores only\",\"\\n\")\n",
    "\n",
    "grid_mean_scores = bestF.cv_results_['mean_test_score']\n",
    "print(grid_mean_scores)\n",
    "\n",
    "# examine the best model\n",
    "print(\"\\n\",\"**examine the best model\",\"\\n\")\n",
    "\n",
    "print(bestF.best_score_)\n",
    "print(bestF.best_params_)\n",
    "print(bestF.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'max_depth': 25, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best score is 0.8039130434782609\n"
     ]
    }
   ],
   "source": [
    "#Print the tured parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(bestF.best_params_))\n",
    "print(\"Best score is {}\".format(bestF.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestOpt = RandomForestClassifier(random_state = 1, max_depth = 25, n_estimators = 400, min_samples_split = 2) #เปลี่ยนตาม cell 8\n",
    "             \n",
    "modelOpt = forestOpt.fit(X, y)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv( '/home/yupaporn/codes/USAI/FVvalidation_5FP_RF_5FP_fold7_1.csv') #เปลี่ยนชื่อไฟล์ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>Class</th>\n",
       "      <th>SubPosition</th>\n",
       "      <th>Views</th>\n",
       "      <th>Sub_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.173976</td>\n",
       "      <td>-0.177463</td>\n",
       "      <td>0.433697</td>\n",
       "      <td>0.100809</td>\n",
       "      <td>-0.128020</td>\n",
       "      <td>-0.120812</td>\n",
       "      <td>-0.150787</td>\n",
       "      <td>0.219978</td>\n",
       "      <td>0.335342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326435</td>\n",
       "      <td>-0.175498</td>\n",
       "      <td>-0.195850</td>\n",
       "      <td>0.775480</td>\n",
       "      <td>0.787809</td>\n",
       "      <td>-0.119870</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P52</td>\n",
       "      <td>FP-C</td>\n",
       "      <td>AB01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.043236</td>\n",
       "      <td>0.577851</td>\n",
       "      <td>-0.184282</td>\n",
       "      <td>0.418325</td>\n",
       "      <td>0.579166</td>\n",
       "      <td>-0.040894</td>\n",
       "      <td>0.556999</td>\n",
       "      <td>0.358772</td>\n",
       "      <td>0.070719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173138</td>\n",
       "      <td>0.823604</td>\n",
       "      <td>0.550526</td>\n",
       "      <td>-0.116387</td>\n",
       "      <td>-0.169571</td>\n",
       "      <td>0.777883</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P2</td>\n",
       "      <td>FP-A</td>\n",
       "      <td>AB02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.156909</td>\n",
       "      <td>-0.195046</td>\n",
       "      <td>0.347664</td>\n",
       "      <td>0.556901</td>\n",
       "      <td>-0.097679</td>\n",
       "      <td>-0.162777</td>\n",
       "      <td>-0.148226</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>0.114956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220005</td>\n",
       "      <td>-0.161138</td>\n",
       "      <td>-0.219117</td>\n",
       "      <td>0.300080</td>\n",
       "      <td>0.100927</td>\n",
       "      <td>-0.112175</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P51</td>\n",
       "      <td>FP-C</td>\n",
       "      <td>AB02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>0.699824</td>\n",
       "      <td>-0.076951</td>\n",
       "      <td>0.501103</td>\n",
       "      <td>0.602246</td>\n",
       "      <td>-0.021318</td>\n",
       "      <td>0.225625</td>\n",
       "      <td>0.605132</td>\n",
       "      <td>-0.073835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145393</td>\n",
       "      <td>0.583961</td>\n",
       "      <td>0.250047</td>\n",
       "      <td>-0.084115</td>\n",
       "      <td>-0.215513</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P1</td>\n",
       "      <td>FP-A</td>\n",
       "      <td>AB02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.305695</td>\n",
       "      <td>0.313379</td>\n",
       "      <td>-0.145852</td>\n",
       "      <td>-0.077773</td>\n",
       "      <td>0.058768</td>\n",
       "      <td>0.874340</td>\n",
       "      <td>-0.097994</td>\n",
       "      <td>0.634504</td>\n",
       "      <td>-0.012574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141696</td>\n",
       "      <td>0.398475</td>\n",
       "      <td>0.293077</td>\n",
       "      <td>0.137701</td>\n",
       "      <td>0.051385</td>\n",
       "      <td>0.880231</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>P31</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>AB02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>652</td>\n",
       "      <td>-0.026421</td>\n",
       "      <td>-0.165454</td>\n",
       "      <td>-0.208760</td>\n",
       "      <td>-0.044831</td>\n",
       "      <td>-0.018537</td>\n",
       "      <td>-0.125202</td>\n",
       "      <td>-0.210612</td>\n",
       "      <td>-0.099431</td>\n",
       "      <td>-0.141840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164277</td>\n",
       "      <td>0.301787</td>\n",
       "      <td>-0.224241</td>\n",
       "      <td>-0.031287</td>\n",
       "      <td>-0.095794</td>\n",
       "      <td>0.041673</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P32</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>653</td>\n",
       "      <td>-0.086747</td>\n",
       "      <td>-0.155141</td>\n",
       "      <td>-0.068611</td>\n",
       "      <td>0.098978</td>\n",
       "      <td>-0.053980</td>\n",
       "      <td>0.450030</td>\n",
       "      <td>-0.148814</td>\n",
       "      <td>0.391194</td>\n",
       "      <td>0.122927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177498</td>\n",
       "      <td>-0.180776</td>\n",
       "      <td>0.089382</td>\n",
       "      <td>0.317262</td>\n",
       "      <td>0.239469</td>\n",
       "      <td>0.463252</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P42</td>\n",
       "      <td>FP-B</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>654</td>\n",
       "      <td>-0.181447</td>\n",
       "      <td>-0.176637</td>\n",
       "      <td>0.562008</td>\n",
       "      <td>0.283786</td>\n",
       "      <td>-0.067406</td>\n",
       "      <td>-0.210617</td>\n",
       "      <td>-0.211688</td>\n",
       "      <td>-0.146790</td>\n",
       "      <td>0.360520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179503</td>\n",
       "      <td>-0.164411</td>\n",
       "      <td>-0.202408</td>\n",
       "      <td>0.361486</td>\n",
       "      <td>0.537691</td>\n",
       "      <td>-0.142212</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P52</td>\n",
       "      <td>FP-C</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>655</td>\n",
       "      <td>-0.141193</td>\n",
       "      <td>-0.213262</td>\n",
       "      <td>0.686296</td>\n",
       "      <td>0.379133</td>\n",
       "      <td>0.137676</td>\n",
       "      <td>-0.156439</td>\n",
       "      <td>-0.174663</td>\n",
       "      <td>-0.066849</td>\n",
       "      <td>0.717559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873334</td>\n",
       "      <td>-0.220589</td>\n",
       "      <td>-0.227014</td>\n",
       "      <td>0.344218</td>\n",
       "      <td>0.269593</td>\n",
       "      <td>-0.166574</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P61</td>\n",
       "      <td>FP-C</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>656</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>-0.006268</td>\n",
       "      <td>-0.019261</td>\n",
       "      <td>0.267096</td>\n",
       "      <td>0.318149</td>\n",
       "      <td>-0.194463</td>\n",
       "      <td>-0.145095</td>\n",
       "      <td>-0.231056</td>\n",
       "      <td>-0.018640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140570</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>-0.241411</td>\n",
       "      <td>-0.125243</td>\n",
       "      <td>-0.168052</td>\n",
       "      <td>-0.057616</td>\n",
       "      <td>Normal</td>\n",
       "      <td>P8</td>\n",
       "      <td>FP-E</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows × 2053 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0             0 -0.173976 -0.177463  0.433697  0.100809 -0.128020 -0.120812   \n",
       "1             1  0.043236  0.577851 -0.184282  0.418325  0.579166 -0.040894   \n",
       "2             2 -0.156909 -0.195046  0.347664  0.556901 -0.097679 -0.162777   \n",
       "3             3 -0.038033  0.699824 -0.076951  0.501103  0.602246 -0.021318   \n",
       "4             4  0.305695  0.313379 -0.145852 -0.077773  0.058768  0.874340   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "652         652 -0.026421 -0.165454 -0.208760 -0.044831 -0.018537 -0.125202   \n",
       "653         653 -0.086747 -0.155141 -0.068611  0.098978 -0.053980  0.450030   \n",
       "654         654 -0.181447 -0.176637  0.562008  0.283786 -0.067406 -0.210617   \n",
       "655         655 -0.141193 -0.213262  0.686296  0.379133  0.137676 -0.156439   \n",
       "656         656  0.008557 -0.006268 -0.019261  0.267096  0.318149 -0.194463   \n",
       "\n",
       "            6         7         8  ...      2042      2043      2044  \\\n",
       "0   -0.150787  0.219978  0.335342  ...  0.326435 -0.175498 -0.195850   \n",
       "1    0.556999  0.358772  0.070719  ... -0.173138  0.823604  0.550526   \n",
       "2   -0.148226  0.047419  0.114956  ...  0.220005 -0.161138 -0.219117   \n",
       "3    0.225625  0.605132 -0.073835  ... -0.145393  0.583961  0.250047   \n",
       "4   -0.097994  0.634504 -0.012574  ... -0.141696  0.398475  0.293077   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "652 -0.210612 -0.099431 -0.141840  ... -0.164277  0.301787 -0.224241   \n",
       "653 -0.148814  0.391194  0.122927  ... -0.177498 -0.180776  0.089382   \n",
       "654 -0.211688 -0.146790  0.360520  ...  0.179503 -0.164411 -0.202408   \n",
       "655 -0.174663 -0.066849  0.717559  ...  0.873334 -0.220589 -0.227014   \n",
       "656 -0.145095 -0.231056 -0.018640  ... -0.140570  0.002586 -0.241411   \n",
       "\n",
       "         2045      2046      2047     Class  SubPosition  Views  Sub_class  \n",
       "0    0.775480  0.787809 -0.119870  Abnormal          P52   FP-C       AB01  \n",
       "1   -0.116387 -0.169571  0.777883  Abnormal           P2   FP-A       AB02  \n",
       "2    0.300080  0.100927 -0.112175  Abnormal          P51   FP-C       AB02  \n",
       "3   -0.084115 -0.215513  0.816456  Abnormal           P1   FP-A       AB02  \n",
       "4    0.137701  0.051385  0.880231  Abnormal          P31   FP-B       AB02  \n",
       "..        ...       ...       ...       ...          ...    ...        ...  \n",
       "652 -0.031287 -0.095794  0.041673    Normal          P32   FP-B     Normal  \n",
       "653  0.317262  0.239469  0.463252    Normal          P42   FP-B     Normal  \n",
       "654  0.361486  0.537691 -0.142212    Normal          P52   FP-C     Normal  \n",
       "655  0.344218  0.269593 -0.166574    Normal          P61   FP-C     Normal  \n",
       "656 -0.125243 -0.168052 -0.057616    Normal           P8   FP-E     Normal  \n",
       "\n",
       "[657 rows x 2053 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657, 2048)\n",
      "(657,)\n"
     ]
    }
   ],
   "source": [
    "X_test = dataframe.iloc[:,1:2049]\n",
    "y_test = dataframe.iloc[:,2049]\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Abnormal\n",
       "1      Abnormal\n",
       "2      Abnormal\n",
       "3      Abnormal\n",
       "4      Abnormal\n",
       "         ...   \n",
       "652      Normal\n",
       "653      Normal\n",
       "654      Normal\n",
       "655      Normal\n",
       "656      Normal\n",
       "Name: Class, Length: 657, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelOpt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116 112]\n",
      " [ 27 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.81      0.51      0.63       228\n",
      "      Normal       0.78      0.94      0.85       429\n",
      "\n",
      "    accuracy                           0.79       657\n",
      "   macro avg       0.80      0.72      0.74       657\n",
      "weighted avg       0.79      0.79      0.77       657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Marking the Confusion Matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))#performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 21.5, 'Predicted label')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\") #Blues,Oranges,Reds\n",
    "ax.set_title('Confusion matrix',fontsize=20)\n",
    "ax.set_ylabel('True label',fontsize=18)\n",
    "ax.set_xlabel('Predicted label',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 112 27 402\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(TN, FP, FN, TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model\n",
    "\n",
    "import pickle\n",
    "os.chdir('/media/tohn/SSD/ModelTrainByImages/R2_7/models/')\n",
    "filename = \"modelrf_5FP_AN_fold7_1.pkl\" #เปลี่ยนชื่อไฟล์ Train random forest\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(modelOpt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load model\n",
    "\n",
    "# with open(filename, 'rb') as file:\n",
    "#     model = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
